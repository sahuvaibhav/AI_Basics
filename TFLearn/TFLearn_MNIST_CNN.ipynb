{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn.datasets.mnist as mnist\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN using TFLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8599  | total loss: \u001b[1m\u001b[32m0.07308\u001b[0m\u001b[0m | time: 118.256s\n",
      "| Adam | epoch: 010 | loss: 0.07308 - acc: 0.9866 -- iter: 54976/55000\n",
      "Training Step: 8600  | total loss: \u001b[1m\u001b[32m0.07088\u001b[0m\u001b[0m | time: 124.174s\n",
      "| Adam | epoch: 010 | loss: 0.07088 - acc: 0.9864 | val_loss: 0.06737 - val_acc: 0.9832 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "X, Y, test_x, test_y = mnist.load_data(one_hot=True)\n",
    "\n",
    "X = X.reshape([-1, 28, 28, 1])\n",
    "test_x = test_x.reshape([-1, 28, 28, 1])\n",
    "\n",
    "convnet = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet)\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id='mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:E:\\Course\\AI_Basics\\Tensorflow\\modelCnnTFlearn.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save('modelCnnTFlearn.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\Course\\AI_Basics\\Tensorflow\\modelCnnTFlearn.model\n"
     ]
    }
   ],
   "source": [
    "model.load('modelCnnTFlearn.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Trained Model\n",
    "\n",
    "To predict having the model graph in memory is necessary. Network Grapg is all the code \"convenet.....\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2dd65fc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  1\n"
     ]
    }
   ],
   "source": [
    "def print_test_image(image_index):\n",
    "    image = test_x[image_index]\n",
    "    image = np.array(image, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "image_index = 2\n",
    "print_test_image(image_index)\n",
    "print(\"Predicted: \",np.argmax(np.round(model.predict([test_x[image_index]])[0]) ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
