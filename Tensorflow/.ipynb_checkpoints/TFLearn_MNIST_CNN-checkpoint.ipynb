{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import tflearn.datasets.mnist as mnist\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN using TFLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8599  | total loss: \u001b[1m\u001b[32m0.07308\u001b[0m\u001b[0m | time: 118.256s\n",
      "| Adam | epoch: 010 | loss: 0.07308 - acc: 0.9866 -- iter: 54976/55000\n",
      "Training Step: 8600  | total loss: \u001b[1m\u001b[32m0.07088\u001b[0m\u001b[0m | time: 124.174s\n",
      "| Adam | epoch: 010 | loss: 0.07088 - acc: 0.9864 | val_loss: 0.06737 - val_acc: 0.9832 -- iter: 55000/55000\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "X, Y, test_x, test_y = mnist.load_data(one_hot=True)\n",
    "\n",
    "X = X.reshape([-1, 28, 28, 1])\n",
    "test_x = test_x.reshape([-1, 28, 28, 1])\n",
    "\n",
    "convnet = input_data(shape=[None, 28, 28, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 10, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet)\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id='mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:E:\\Course\\AI_Basics\\Tensorflow\\modelCnnTFlearn.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save('modelCnnTFlearn.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from E:\\Course\\AI_Basics\\Tensorflow\\modelCnnTFlearn.model\n"
     ]
    }
   ],
   "source": [
    "model.load('modelCnnTFlearn.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Trained Model\n",
    "\n",
    "To predict having the model graph in memory is necessary. Network Grapg is all the code \"convenet.....\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print( np.round(model.predict([test_x[1]])[0]) )\n",
    "print(test_y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b2dd65fc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_test_image(image_index):\n",
    "    image = test_x[image_index]\n",
    "    image = np.array(image, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "print_test_image(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
