{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows, img_cols = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,111,946.0\n",
      "Trainable params: 1,111,946.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Start with a simple sequential model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model to put it all together.\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 112s - loss: 0.2341 - acc: 0.9270 - val_loss: 0.0452 - val_acc: 0.9864\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 110s - loss: 0.0697 - acc: 0.9792 - val_loss: 0.0320 - val_acc: 0.9899\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 110s - loss: 0.0480 - acc: 0.9853 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 115s - loss: 0.0411 - acc: 0.9873 - val_loss: 0.0244 - val_acc: 0.9922\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 126s - loss: 0.0336 - acc: 0.9897 - val_loss: 0.0212 - val_acc: 0.9934\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 126s - loss: 0.0296 - acc: 0.9909 - val_loss: 0.0225 - val_acc: 0.9922\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 116s - loss: 0.0257 - acc: 0.9920 - val_loss: 0.0210 - val_acc: 0.9932\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 113s - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0224 - val_acc: 0.9932\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 117s - loss: 0.0199 - acc: 0.9933 - val_loss: 0.0216 - val_acc: 0.9936\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 115s - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0192 - val_acc: 0.9935\n",
      "Test loss: 0.01924133208225662\n",
      "Test accuracy: 0.9935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "model.save(\"KerasMNISTCNN.model\")\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST CNN Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"KerasMNISTCNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n",
      "Predicted: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25b34626668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def print_test_image(image_index):\n",
    "    image = x_test[image_index]\n",
    "    image = np.array(image, dtype='float')\n",
    "    pixels = image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "image_index = 3\n",
    "print(\"Predicted:\",model.predict_classes(x_test[image_index].reshape((1,28,28,1)))[0])\n",
    "print_test_image(image_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
